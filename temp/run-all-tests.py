#!/usr/bin/env python3
"""
Excel MCP Server - ç»¼åˆæµ‹è¯•è¿è¡Œè„šæœ¬

è¿™æ˜¯ä¸€ä¸ªå…¨é¢çš„æµ‹è¯•è¿è¡Œå™¨ï¼ŒåŒ…å«ï¼š
1. æµ‹è¯•ç¯å¢ƒæ£€æŸ¥
2. ä¾èµ–é¡¹éªŒè¯
3. å•å…ƒæµ‹è¯•è¿è¡Œ
4. é›†æˆæµ‹è¯•è¿è¡Œ
5. æ€§èƒ½æµ‹è¯•è¿è¡Œ
6. è¦†ç›–ç‡æŠ¥å‘Šç”Ÿæˆ
7. ç»“æœæ±‡æ€»å’ŒæŠ¥å‘Š
8. é”™è¯¯åˆ†æå’Œå»ºè®®

ä½¿ç”¨æ–¹æ³•:
    python run-all-tests.py                    # è¿è¡Œæ‰€æœ‰æ£€æŸ¥å’Œæµ‹è¯•
    python run-all-tests.py --quick           # å¿«é€Ÿæ¨¡å¼ï¼ˆè·³è¿‡æ…¢é€Ÿæµ‹è¯•ï¼‰
    python run-all-tests.py --coverage-only   # ä»…è¿è¡Œè¦†ç›–ç‡æµ‹è¯•
    python run-all-tests.py --performance     # ä»…è¿è¡Œæ€§èƒ½æµ‹è¯•
    python run-all-tests.py --validate-only   # ä»…éªŒè¯ç¯å¢ƒå’Œä¾èµ–
"""

import argparse
import asyncio
import json
import os
import platform
import shutil
import subprocess
import sys
import time
import traceback
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any

# å¯é€‰ä¾èµ–å¤„ç†
try:
    import psutil
    HAS_PSUTIL = True
except ImportError:
    HAS_PSUTIL = False

# é¢œè‰²è¾“å‡ºæ”¯æŒ
class Colors:
    """ç»ˆç«¯é¢œè‰²å¸¸é‡"""
    RESET = '\033[0m'
    RED = '\033[91m'
    GREEN = '\033[92m'
    YELLOW = '\033[93m'
    BLUE = '\033[94m'
    PURPLE = '\033[95m'
    CYAN = '\033[96m'
    WHITE = '\033[97m'
    BOLD = '\033[1m'

# Windows å…¼å®¹æ€§å¤„ç†
if platform.system() == 'Windows':
    # ç¦ç”¨ ANSI é¢œè‰²ï¼Œæˆ–è€…å¯ç”¨ Windows 10+ çš„ ANSI æ”¯æŒ
    try:
        import ctypes
        kernel32 = ctypes.windll.kernel32
        kernel32.SetConsoleMode(kernel32.GetStdHandle(-11), 7)
    except:
        # å¦‚æœå¤±è´¥ï¼Œåˆ›å»ºæ— é¢œè‰²çš„ç‰ˆæœ¬
        class Colors:
            RESET = ''
            RED = ''
            GREEN = ''
            YELLOW = ''
            BLUE = ''
            PURPLE = ''
            CYAN = ''
            WHITE = ''
            BOLD = ''

class TestResult:
    """æµ‹è¯•ç»“æœæ•°æ®ç±»"""
    def __init__(self, name: str, category: str):
        self.name = name
        self.category = category
        self.success = False
        self.duration = 0.0
        self.stdout = ""
        self.stderr = ""
        self.error_message = ""
        self.test_count = 0
        self.failure_count = 0
        self.error_count = 0
        self.skip_count = 0
        self.coverage_percentage = 0.0

    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        return {
            'name': self.name,
            'category': self.category,
            'success': self.success,
            'duration': self.duration,
            'test_count': self.test_count,
            'failure_count': self.failure_count,
            'error_count': self.error_count,
            'skip_count': self.skip_count,
            'coverage_percentage': self.coverage_percentage,
            'error_message': self.error_message
        }

class EnvironmentChecker:
    """ç¯å¢ƒæ£€æŸ¥å™¨"""

    def __init__(self):
        self.project_root = Path(__file__).parent
        self.src_path = self.project_root / "src"
        self.tests_path = self.project_root / "tests"
        self.requirements = {
            'python_version': '3.10',
            'required_modules': [
                'fastmcp', 'openpyxl', 'mcp', 'xlcalculator',
                'formulas', 'xlwings'
            ],
            'dev_modules': [
                'pytest', 'pytest-asyncio', 'pytest-cov',
                'pytest-mock', 'pytest-xdist'
            ]
        }

    def check_python_version(self) -> Tuple[bool, str]:
        """æ£€æŸ¥Pythonç‰ˆæœ¬"""
        version = sys.version_info
        required_version = tuple(map(int, self.requirements['python_version'].split('.')))

        if version >= required_version:
            return True, f"Python {version.major}.{version.minor}.{version.micro} OK"
        else:
            return False, f"Python {version.major}.{version.minor}.{version.micro} FAIL (éœ€è¦ >= {self.requirements['python_version']})"

    def check_project_structure(self) -> Tuple[bool, List[str]]:
        """æ£€æŸ¥é¡¹ç›®ç»“æ„"""
        required_dirs = ['src', 'src/api', 'src/core', 'src/utils', 'tests']
        required_files = [
            'src/server.py',
            'src/api/excel_operations.py',
            'pyproject.toml',
            'CLAUDE.md'
        ]

        missing_items = []

        for dir_path in required_dirs:
            if not (self.project_root / dir_path).exists():
                missing_items.append(f"ç›®å½•: {dir_path}")

        for file_path in required_files:
            if not (self.project_root / file_path).exists():
                missing_items.append(f"æ–‡ä»¶: {file_path}")

        return len(missing_items) == 0, missing_items

    def check_modules(self) -> Tuple[bool, List[str]]:
        """æ£€æŸ¥Pythonæ¨¡å—"""
        missing_modules = []

        for module in self.requirements['required_modules']:
            try:
                __import__(module)
            except ImportError:
                missing_modules.append(module)

        return len(missing_modules) == 0, missing_modules

    def check_dev_modules(self) -> Tuple[bool, List[str]]:
        """æ£€æŸ¥å¼€å‘ä¾èµ–æ¨¡å—"""
        missing_modules = []

        for module in self.requirements['dev_modules']:
            try:
                __import__(module.replace('-', '_'))
            except ImportError:
                missing_modules.append(module)

        return len(missing_modules) == 0, missing_modules

    def check_system_resources(self) -> Dict[str, Any]:
        """æ£€æŸ¥ç³»ç»Ÿèµ„æº"""
        if HAS_PSUTIL:
            memory = psutil.virtual_memory()
            disk = psutil.disk_usage(str(self.project_root))

            return {
                'cpu_count': psutil.cpu_count(),
                'memory_total_gb': round(memory.total / (1024**3), 2),
                'memory_available_gb': round(memory.available / (1024**3), 2),
                'memory_percent': memory.percent,
                'disk_free_gb': round(disk.free / (1024**3), 2),
                'disk_total_gb': round(disk.total / (1024**3), 2),
            }
        else:
            # åŸºæœ¬ç³»ç»Ÿä¿¡æ¯ï¼Œä¸ä¾èµ–psutil
            import os
            try:
                disk_usage = os.statvfs(str(self.project_root)) if hasattr(os, 'statvfs') else None
                disk_free = round(disk_usage.f_frsize * disk_usage.f_bavail / (1024**3), 2) if disk_usage else "Unknown"
            except:
                disk_free = "Unknown"

            return {
                'cpu_count': os.cpu_count() if hasattr(os, 'cpu_count') else "Unknown",
                'memory_total_gb': "Unknown",
                'memory_available_gb': "Unknown",
                'memory_percent': "Unknown",
                'disk_free_gb': disk_free,
                'disk_total_gb': "Unknown",
            }

class TestRunner:
    """æµ‹è¯•è¿è¡Œå™¨"""

    def __init__(self, project_root: Path):
        self.project_root = project_root
        self.results: List[TestResult] = []
        self.start_time = time.time()

    def run_command(self, cmd: List[str], timeout: int = 300, capture_output: bool = True) -> Tuple[bool, str, str]:
        """è¿è¡Œå‘½ä»¤å¹¶è¿”å›ç»“æœ"""
        try:
            print(f"  æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}")

            result = subprocess.run(
                cmd,
                cwd=str(self.project_root),
                timeout=timeout,
                capture_output=capture_output,
                text=True,
                encoding='utf-8'
            )

            return result.returncode == 0, result.stdout, result.stderr

        except subprocess.TimeoutExpired:
            return False, "", f"å‘½ä»¤æ‰§è¡Œè¶…æ—¶ ({timeout}ç§’)"
        except Exception as e:
            return False, "", f"å‘½ä»¤æ‰§è¡Œå¼‚å¸¸: {str(e)}"

    def parse_pytest_output(self, stdout: str) -> Dict[str, int]:
        """è§£æpytestè¾“å‡ºï¼Œæå–æµ‹è¯•ç»Ÿè®¡ä¿¡æ¯"""
        stats = {
            'test_count': 0,
            'failure_count': 0,
            'error_count': 0,
            'skip_count': 0
        }

        # æŸ¥æ‰¾pytestçš„æ€»ç»“è¡Œ
        lines = stdout.split('\n')
        for line in lines:
            if ' passed' in line or ' failed' in line or ' errors' in line or ' skipped' in line:
                # ç¤ºä¾‹: "10 passed, 2 failed, 1 errors, 3 skipped in 15.3s"
                parts = line.split()[0]  # "10"
                if parts.replace(',', '').isdigit():
                    stats['test_count'] = int(parts.replace(',', ''))

                if ' failed' in line:
                    for i, part in enumerate(line.split()):
                        if part.isdigit() and 'failed' in line.split()[i+1]:
                            stats['failure_count'] = int(part)
                            break

                if ' errors' in line:
                    for i, part in enumerate(line.split()):
                        if part.isdigit() and 'errors' in line.split()[i+1]:
                            stats['error_count'] = int(part)
                            break

                if ' skipped' in line:
                    for i, part in enumerate(line.split()):
                        if part.isdigit() and 'skipped' in line.split()[i+1]:
                            stats['skip_count'] = int(part)
                            break

        return stats

    def parse_coverage_output(self, stdout: str) -> float:
        """è§£æè¦†ç›–ç‡è¾“å‡º"""
        lines = stdout.split('\n')
        for line in lines:
            if 'TOTAL' in line and '%' in line:
                # ç¤ºä¾‹: "TOTAL                            15      5    67%"
                parts = line.strip().split()
                for part in parts:
                    if part.endswith('%'):
                        try:
                            return float(part.rstrip('%'))
                        except ValueError:
                            pass
        return 0.0

    def run_unit_tests(self, quick_mode: bool = False) -> TestResult:
        """è¿è¡Œå•å…ƒæµ‹è¯•"""
        result = TestResult("å•å…ƒæµ‹è¯•", "unit")
        start_time = time.time()

        cmd = [
            "python", "-m", "pytest", "tests/",
            "-m", "not integration and not performance and not slow",
            "-v", "--tb=short", "--color=yes"
        ]

        if quick_mode:
            cmd.extend(["--maxfail=5", "-x"])  # å¿«é€Ÿå¤±è´¥

        success, stdout, stderr = self.run_command(cmd, timeout=600)

        result.duration = time.time() - start_time
        result.success = success
        result.stdout = stdout
        result.stderr = stderr

        # è§£ææµ‹è¯•ç»Ÿè®¡
        stats = self.parse_pytest_output(stdout)
        result.test_count = stats['test_count']
        result.failure_count = stats['failure_count']
        result.error_count = stats['error_count']
        result.skip_count = stats['skip_count']

        if not success:
            result.error_message = stderr or "å•å…ƒæµ‹è¯•æ‰§è¡Œå¤±è´¥"

        return result

    def run_integration_tests(self) -> TestResult:
        """è¿è¡Œé›†æˆæµ‹è¯•"""
        result = TestResult("é›†æˆæµ‹è¯•", "integration")
        start_time = time.time()

        cmd = [
            "python", "-m", "pytest", "tests/",
            "-m", "integration",
            "-v", "--tb=short", "--color=yes"
        ]

        success, stdout, stderr = self.run_command(cmd, timeout=900)

        result.duration = time.time() - start_time
        result.success = success
        result.stdout = stdout
        result.stderr = stderr

        stats = self.parse_pytest_output(stdout)
        result.test_count = stats['test_count']
        result.failure_count = stats['failure_count']
        result.error_count = stats['error_count']
        result.skip_count = stats['skip_count']

        if not success:
            result.error_message = stderr or "é›†æˆæµ‹è¯•æ‰§è¡Œå¤±è´¥"

        return result

    def run_performance_tests(self) -> TestResult:
        """è¿è¡Œæ€§èƒ½æµ‹è¯•"""
        result = TestResult("æ€§èƒ½æµ‹è¯•", "performance")
        start_time = time.time()

        cmd = [
            "python", "-m", "pytest", "tests/",
            "-m", "performance",
            "-v", "-s", "--tb=short", "--color=yes"
        ]

        success, stdout, stderr = self.run_command(cmd, timeout=1200)

        result.duration = time.time() - start_time
        result.success = success
        result.stdout = stdout
        result.stderr = stderr

        stats = self.parse_pytest_output(stdout)
        result.test_count = stats['test_count']
        result.failure_count = stats['failure_count']
        result.error_count = stats['error_count']
        result.skip_count = stats['skip_count']

        if not success:
            result.error_message = stderr or "æ€§èƒ½æµ‹è¯•æ‰§è¡Œå¤±è´¥"

        return result

    def run_coverage_tests(self) -> TestResult:
        """è¿è¡Œè¦†ç›–ç‡æµ‹è¯•"""
        result = TestResult("è¦†ç›–ç‡æµ‹è¯•", "coverage")
        start_time = time.time()

        cmd = [
            "python", "-m", "pytest", "tests/",
            "--cov=src",
            "--cov-report=term-missing",
            "--cov-report=html",
            "--cov-report=xml",
            "--cov-fail-under=70",
            "-v", "--tb=short", "--color=yes"
        ]

        success, stdout, stderr = self.run_command(cmd, timeout=900)

        result.duration = time.time() - start_time
        result.success = success
        result.stdout = stdout
        result.stderr = stderr

        # è§£æè¦†ç›–ç‡ç™¾åˆ†æ¯”
        result.coverage_percentage = self.parse_coverage_output(stdout)

        stats = self.parse_pytest_output(stdout)
        result.test_count = stats['test_count']
        result.failure_count = stats['failure_count']
        result.error_count = stats['error_count']
        result.skip_count = stats['skip_count']

        if not success:
            result.error_message = stderr or "è¦†ç›–ç‡æµ‹è¯•æ‰§è¡Œå¤±è´¥"

        return result

    def run_security_tests(self) -> TestResult:
        """è¿è¡Œå®‰å…¨æµ‹è¯•"""
        result = TestResult("å®‰å…¨æµ‹è¯•", "security")
        start_time = time.time()

        cmd = [
            "python", "-m", "pytest", "tests/",
            "-m", "security",
            "-v", "--tb=short", "--color=yes"
        ]

        success, stdout, stderr = self.run_command(cmd, timeout=600)

        result.duration = time.time() - start_time
        result.success = success
        result.stdout = stdout
        result.stderr = stderr

        stats = self.parse_pytest_output(stdout)
        result.test_count = stats['test_count']
        result.failure_count = stats['failure_count']
        result.error_count = stats['error_count']
        result.skip_count = stats['skip_count']

        if not success:
            result.error_message = stderr or "å®‰å…¨æµ‹è¯•æ‰§è¡Œå¤±è´¥"

        return result

class ReportGenerator:
    """æŠ¥å‘Šç”Ÿæˆå™¨"""

    def __init__(self, results: List[TestResult], env_info: Dict[str, Any]):
        self.results = results
        self.env_info = env_info
        self.total_duration = sum(r.duration for r in results)

    def print_summary(self):
        """æ‰“å°æµ‹è¯•æ€»ç»“"""
        print(f"\n{Colors.BOLD}{Colors.CYAN}{'='*80}")
        print("æµ‹è¯•æ‰§è¡Œæ€»ç»“")
        print(f"{'='*80}{Colors.RESET}")

        total_tests = sum(r.test_count for r in self.results)
        total_failures = sum(r.failure_count for r in self.results)
        total_errors = sum(r.error_count for r in self.results)
        total_skips = sum(r.skip_count for r in self.results)

        # æ€»ä½“çŠ¶æ€
        all_success = all(r.success for r in self.results)
        status_color = Colors.GREEN if all_success else Colors.RED
        status_text = "âœ“ å…¨éƒ¨é€šè¿‡" if all_success else "âœ— å­˜åœ¨å¤±è´¥"

        print(f"\n{Colors.BOLD}æ€»ä½“çŠ¶æ€: {status_color}{status_text}{Colors.RESET}")
        print(f"æ€»æ‰§è¡Œæ—¶é—´: {self.total_duration:.2f} ç§’")
        print(f"æµ‹è¯•æ€»æ•°: {total_tests}")
        print(f"å¤±è´¥æ•°é‡: {total_failures}")
        print(f"é”™è¯¯æ•°é‡: {total_errors}")
        print(f"è·³è¿‡æ•°é‡: {total_skips}")

        # åˆ†ç±»ç»“æœ
        print(f"\n{Colors.BOLD}åˆ†ç±»ç»“æœ:{Colors.RESET}")
        for result in self.results:
            status_color = Colors.GREEN if result.success else Colors.RED
            status_icon = "âœ“" if result.success else "âœ—"

            coverage_info = ""
            if result.coverage_percentage > 0:
                coverage_color = Colors.GREEN if result.coverage_percentage >= 70 else Colors.YELLOW
                coverage_info = f" (è¦†ç›–ç‡: {coverage_color}{result.coverage_percentage:.1f}%{Colors.RESET})"

            print(f"  {status_icon} {result.name}: {status_color}{result.category}{Colors.RESET} "
                  f"({result.duration:.1f}s, {result.test_count} æµ‹è¯•){coverage_info}")

            if not result.success:
                print(f"    é”™è¯¯: {Colors.RED}{result.error_message[:100]}{Colors.RESET}")

    def print_environment_info(self):
        """æ‰“å°ç¯å¢ƒä¿¡æ¯"""
        print(f"\n{Colors.BOLD}{Colors.BLUE}ç¯å¢ƒä¿¡æ¯{Colors.RESET}")
        print(f"Pythonç‰ˆæœ¬: {self.env_info.get('python_version', 'Unknown')}")
        print(f"æ“ä½œç³»ç»Ÿ: {platform.system()} {platform.release()}")
        print(f"CPUæ ¸å¿ƒæ•°: {self.env_info.get('system_resources', {}).get('cpu_count', 'Unknown')}")
        print(f"å¯ç”¨å†…å­˜: {self.env_info.get('system_resources', {}).get('memory_available_gb', 'Unknown')} GB")
        print(f"ç£ç›˜ç©ºé—´: {self.env_info.get('system_resources', {}).get('disk_free_gb', 'Unknown')} GB")

    def print_failed_analysis(self):
        """æ‰“å°å¤±è´¥åˆ†æ"""
        failed_results = [r for r in self.results if not r.success]

        if not failed_results:
            print(f"\n{Colors.GREEN}{Colors.BOLD}ğŸ‰ æ‰€æœ‰æµ‹è¯•éƒ½é€šè¿‡äº†ï¼{Colors.RESET}")
            return

        print(f"\n{Colors.RED}{Colors.BOLD}å¤±è´¥æµ‹è¯•åˆ†æ{Colors.RESET}")

        for result in failed_results:
            print(f"\n{Colors.RED}â— {result.name} ({result.category}){Colors.RESET}")
            print(f"  é”™è¯¯ä¿¡æ¯: {result.error_message}")

            if result.failure_count > 0:
                print(f"  å¤±è´¥æµ‹è¯•æ•°: {result.failure_count}")
            if result.error_count > 0:
                print(f"  é”™è¯¯æµ‹è¯•æ•°: {result.error_count}")

            # æä¾›å»ºè®®
            print(f"  {Colors.YELLOW}å»ºè®®:{Colors.RESET}")

            if result.category == "unit":
                print("    - æ£€æŸ¥ä»£ç é€»è¾‘æ˜¯å¦æ­£ç¡®")
                print("    - ç¡®è®¤æµ‹è¯•ç”¨ä¾‹æ˜¯å¦è¦†ç›–äº†æ‰€æœ‰è¾¹ç•Œæƒ…å†µ")
                print("    - è¿è¡Œ: python -m pytest tests/test_api_excel_operations.py -v -s")

            elif result.category == "integration":
                print("    - æ£€æŸ¥æ¨¡å—é—´çš„é›†æˆæ˜¯å¦æ­£å¸¸")
                print("    - ç¡®è®¤å¤–éƒ¨ä¾èµ–æ˜¯å¦å¯ç”¨")
                print("    - è¿è¡Œ: python -m pytest tests/test_integration_comprehensive.py -v -s")

            elif result.category == "performance":
                print("    - æ£€æŸ¥ç³»ç»Ÿèµ„æºæ˜¯å¦å……è¶³")
                print("    - ä¼˜åŒ–ç®—æ³•æˆ–å¢åŠ ç¼“å­˜")
                print("    - è¿è¡Œ: python -m pytest tests/test_performance.py -v -s")

            elif result.category == "coverage":
                print("    - å¢åŠ æµ‹è¯•ç”¨ä¾‹ä»¥æé«˜è¦†ç›–ç‡")
                print("    - ç›®æ ‡è¦†ç›–ç‡åº”è¾¾åˆ° 70% ä»¥ä¸Š")
                print("    - æŸ¥çœ‹è¯¦ç»†æŠ¥å‘Š: htmlcov/index.html")

    def save_report(self, filename: str = None):
        """ä¿å­˜æµ‹è¯•æŠ¥å‘Šåˆ°JSONæ–‡ä»¶"""
        if filename is None:
            filename = f"test_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"

        report_data = {
            'timestamp': datetime.now().isoformat(),
            'environment': self.env_info,
            'summary': {
                'total_duration': self.total_duration,
                'total_tests': sum(r.test_count for r in self.results),
                'total_failures': sum(r.failure_count for r in self.results),
                'total_errors': sum(r.error_count for r in self.results),
                'total_skips': sum(r.skip_count for r in self.results),
                'all_success': all(r.success for r in self.results)
            },
            'results': [r.to_dict() for r in self.results]
        }

        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(report_data, f, indent=2, ensure_ascii=False)

        print(f"\n{Colors.CYAN}è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {filename}{Colors.RESET}")

def cleanup_test_artifacts(project_root: Path):
    """æ¸…ç†æµ‹è¯•äº§ç”Ÿçš„ä¸´æ—¶æ–‡ä»¶"""
    print(f"\n{Colors.YELLOW}æ¸…ç†æµ‹è¯•ä¸´æ—¶æ–‡ä»¶...{Colors.RESET}")

    artifacts = [
        ".pytest_cache",
        ".coverage",
        "coverage.xml",
        "htmlcov",
        ".benchmarks",
        "*.pyc",
        "__pycache__"
    ]

    removed_count = 0

    for pattern in artifacts:
        if pattern.startswith("*."):
            # å¤„ç†æ–‡ä»¶æ¨¡å¼
            for file_path in project_root.rglob(pattern[2:]):
                try:
                    file_path.unlink()
                    print(f"  åˆ é™¤æ–‡ä»¶: {file_path.relative_to(project_root)}")
                    removed_count += 1
                except:
                    pass
        else:
            # å¤„ç†ç›®å½•
            artifact_path = project_root / pattern
            if artifact_path.exists():
                try:
                    if artifact_path.is_dir():
                        shutil.rmtree(artifact_path)
                        print(f"  åˆ é™¤ç›®å½•: {pattern}")
                    else:
                        artifact_path.unlink()
                        print(f"  åˆ é™¤æ–‡ä»¶: {pattern}")
                    removed_count += 1
                except Exception as e:
                    print(f"  æ— æ³•åˆ é™¤ {pattern}: {e}")

    print(f"{Colors.GREEN}æ¸…ç†å®Œæˆï¼Œå…±åˆ é™¤ {removed_count} ä¸ªé¡¹ç›®{Colors.RESET}")

def print_banner():
    """æ‰“å°ç¨‹åºæ¨ªå¹…"""
    print(f"{Colors.BOLD}{Colors.CYAN}")
    print("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    print("â•‘         Excel MCP Server - ç»¼åˆæµ‹è¯•è¿è¡Œè„šæœ¬                    â•‘")
    print("â•‘                                                              â•‘")
    print("â•‘  å®Œæ•´çš„æµ‹è¯•è§£å†³æ–¹æ¡ˆï¼šç¯å¢ƒæ£€æŸ¥ã€å•å…ƒæµ‹è¯•ã€é›†æˆæµ‹è¯•ã€            â•‘")
    print("â•‘  æ€§èƒ½æµ‹è¯•ã€è¦†ç›–ç‡åˆ†æå’Œè¯¦ç»†çš„é”™è¯¯æŠ¥å‘Š                        â•‘")
    print("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    print(f"{Colors.RESET}")

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="Excel MCP Server ç»¼åˆæµ‹è¯•è¿è¡Œè„šæœ¬",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  python run-all-tests.py                          # è¿è¡Œæ‰€æœ‰æµ‹è¯•
  python run-all-tests.py --quick                  # å¿«é€Ÿæ¨¡å¼
  python run-all-tests.py --coverage-only          # ä»…è¦†ç›–ç‡æµ‹è¯•
  python run-all-tests.py --performance            # ä»…æ€§èƒ½æµ‹è¯•
  python run-all-tests.py --validate-only          # ä»…éªŒè¯ç¯å¢ƒ
  python run-all-tests.py --cleanup                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
  python run-all-tests.py --report-file my.json    # æŒ‡å®šæŠ¥å‘Šæ–‡ä»¶
        """
    )

    parser.add_argument(
        '--quick', '-q',
        action='store_true',
        help='å¿«é€Ÿæ¨¡å¼ï¼ˆè·³è¿‡æ…¢é€Ÿæµ‹è¯•å’Œæ€§èƒ½æµ‹è¯•ï¼‰'
    )

    parser.add_argument(
        '--coverage-only', '-c',
        action='store_true',
        help='ä»…è¿è¡Œè¦†ç›–ç‡æµ‹è¯•'
    )

    parser.add_argument(
        '--performance', '-p',
        action='store_true',
        help='ä»…è¿è¡Œæ€§èƒ½æµ‹è¯•'
    )

    parser.add_argument(
        '--validate-only', '-v',
        action='store_true',
        help='ä»…éªŒè¯ç¯å¢ƒå’Œä¾èµ–'
    )

    parser.add_argument(
        '--cleanup',
        action='store_true',
        help='æ¸…ç†æµ‹è¯•ä¸´æ—¶æ–‡ä»¶'
    )

    parser.add_argument(
        '--no-color',
        action='store_true',
        help='ç¦ç”¨å½©è‰²è¾“å‡º'
    )

    parser.add_argument(
        '--report-file', '-r',
        type=str,
        help='æŒ‡å®šæµ‹è¯•æŠ¥å‘Šæ–‡ä»¶å'
    )

    args = parser.parse_args()

    # ç¦ç”¨é¢œè‰²è¾“å‡º
    if args.no_color:
        global Colors
        Colors = type('Colors', (), {
            'RESET': '', 'RED': '', 'GREEN': '', 'YELLOW': '',
            'BLUE': '', 'PURPLE': '', 'CYAN': '', 'WHITE': '', 'BOLD': ''
        })()

    print_banner()

    project_root = Path(__file__).parent

    # æ¸…ç†æ¨¡å¼
    if args.cleanup:
        cleanup_test_artifacts(project_root)
        return

    # ç¯å¢ƒæ£€æŸ¥
    print(f"{Colors.BOLD}{Colors.BLUE}ç¬¬ä¸€é˜¶æ®µï¼šç¯å¢ƒæ£€æŸ¥{Colors.RESET}")
    print("-" * 50)

    checker = EnvironmentChecker()
    env_info = {}
    env_valid = True

    # Pythonç‰ˆæœ¬æ£€æŸ¥
    python_ok, python_msg = checker.check_python_version()
    print(f"Pythonç‰ˆæœ¬: {python_msg}")
    if not python_ok:
        env_valid = False

    env_info['python_version'] = python_msg

    # é¡¹ç›®ç»“æ„æ£€æŸ¥
    structure_ok, missing_items = checker.check_project_structure()
    if structure_ok:
        print("é¡¹ç›®ç»“æ„: OK æ‰€æœ‰å¿…éœ€ç›®å½•å’Œæ–‡ä»¶éƒ½å­˜åœ¨")
    else:
        print("é¡¹ç›®ç»“æ„: FAIL ç¼ºå°‘ä»¥ä¸‹é¡¹ç›®:")
        for item in missing_items:
            print(f"  - {item}")
        env_valid = False

    # æ¨¡å—ä¾èµ–æ£€æŸ¥
    modules_ok, missing_modules = checker.check_modules()
    if modules_ok:
        print("æ ¸å¿ƒæ¨¡å—: âœ“ æ‰€æœ‰å¿…éœ€æ¨¡å—éƒ½å·²å®‰è£…")
    else:
        print(f"æ ¸å¿ƒæ¨¡å—: âœ— ç¼ºå°‘ä»¥ä¸‹æ¨¡å—:")
        for module in missing_modules:
            print(f"  - {module}")
        env_valid = False

    # å¼€å‘ä¾èµ–æ£€æŸ¥
    dev_modules_ok, missing_dev_modules = checker.check_dev_modules()
    if dev_modules_ok:
        print("å¼€å‘æ¨¡å—: âœ“ æ‰€æœ‰å¼€å‘æ¨¡å—éƒ½å·²å®‰è£…")
    else:
        print(f"å¼€å‘æ¨¡å—: âœ— ç¼ºå°‘ä»¥ä¸‹å¼€å‘æ¨¡å—:")
        for module in missing_dev_modules:
            print(f"  - {module}")
        print("  å»ºè®®: pip install -e .[dev]")
        # å¼€å‘æ¨¡å—ä¸æ˜¯å¿…é¡»çš„ï¼Œåªè­¦å‘Š

    # ç³»ç»Ÿèµ„æºæ£€æŸ¥
    system_resources = checker.check_system_resources()
    env_info['system_resources'] = system_resources
    print(f"ç³»ç»Ÿèµ„æº: CPU {system_resources['cpu_count']} æ ¸, "
          f"å†…å­˜ {system_resources['memory_available_gb']:.1f}GB å¯ç”¨, "
          f"ç£ç›˜ {system_resources['disk_free_gb']:.1f}GB å¯ç”¨")

    # å¦‚æœç¯å¢ƒéªŒè¯å¤±è´¥ï¼Œé€€å‡º
    if not env_valid:
        print(f"\n{Colors.RED}ç¯å¢ƒéªŒè¯å¤±è´¥ï¼Œè¯·è§£å†³ä¸Šè¿°é—®é¢˜åé‡æ–°è¿è¡Œ{Colors.RESET}")
        sys.exit(1)

    # ä»…éªŒè¯ç¯å¢ƒæ¨¡å¼
    if args.validate_only:
        print(f"\n{Colors.GREEN}ç¯å¢ƒéªŒè¯å®Œæˆï¼{Colors.RESET}")
        return

    # æµ‹è¯•æ‰§è¡Œ
    print(f"\n{Colors.BOLD}{Colors.BLUE}ç¬¬äºŒé˜¶æ®µï¼šæµ‹è¯•æ‰§è¡Œ{Colors.RESET}")
    print("-" * 50)

    runner = TestRunner(project_root)

    # æ ¹æ®å‚æ•°é€‰æ‹©è¿è¡Œçš„æµ‹è¯•
    if args.coverage_only:
        print("è¿è¡Œè¦†ç›–ç‡æµ‹è¯•...")
        result = runner.run_coverage_tests()
        runner.results.append(result)

    elif args.performance:
        print("è¿è¡Œæ€§èƒ½æµ‹è¯•...")
        result = runner.run_performance_tests()
        runner.results.append(result)

    else:
        # å®Œæ•´æµ‹è¯•æµç¨‹
        if args.quick:
            print("å¿«é€Ÿæ¨¡å¼ï¼šè¿è¡ŒåŸºç¡€æµ‹è¯•...")
            # å•å…ƒæµ‹è¯•
            print("è¿è¡Œå•å…ƒæµ‹è¯•...")
            unit_result = runner.run_unit_tests(quick_mode=True)
            runner.results.append(unit_result)

            # å¿«é€Ÿè¦†ç›–ç‡æµ‹è¯•
            print("è¿è¡Œè¦†ç›–ç‡æµ‹è¯•...")
            coverage_result = runner.run_coverage_tests()
            runner.results.append(coverage_result)

        else:
            print("å®Œæ•´æ¨¡å¼ï¼šè¿è¡Œæ‰€æœ‰æµ‹è¯•...")

            # å•å…ƒæµ‹è¯•
            print("è¿è¡Œå•å…ƒæµ‹è¯•...")
            unit_result = runner.run_unit_tests()
            runner.results.append(unit_result)

            # é›†æˆæµ‹è¯•
            print("è¿è¡Œé›†æˆæµ‹è¯•...")
            integration_result = runner.run_integration_tests()
            runner.results.append(integration_result)

            # æ€§èƒ½æµ‹è¯•
            print("è¿è¡Œæ€§èƒ½æµ‹è¯•...")
            performance_result = runner.run_performance_tests()
            runner.results.append(performance_result)

            # å®‰å…¨æµ‹è¯•
            print("è¿è¡Œå®‰å…¨æµ‹è¯•...")
            security_result = runner.run_security_tests()
            runner.results.append(security_result)

            # è¦†ç›–ç‡æµ‹è¯•
            print("è¿è¡Œè¦†ç›–ç‡æµ‹è¯•...")
            coverage_result = runner.run_coverage_tests()
            runner.results.append(coverage_result)

    # ç”ŸæˆæŠ¥å‘Š
    print(f"\n{Colors.BOLD}{Colors.BLUE}ç¬¬ä¸‰é˜¶æ®µï¼šæŠ¥å‘Šç”Ÿæˆ{Colors.RESET}")
    print("-" * 50)

    report_generator = ReportGenerator(runner.results, env_info)
    report_generator.print_environment_info()
    report_generator.print_summary()
    report_generator.print_failed_analysis()

    # ä¿å­˜æŠ¥å‘Š
    report_generator.save_report(args.report_file)

    # æœ€ç»ˆçŠ¶æ€
    all_success = all(r.success for r in runner.results)
    if all_success:
        print(f"\n{Colors.GREEN}{Colors.BOLD}ğŸ‰ æ‰€æœ‰æµ‹è¯•éƒ½æˆåŠŸå®Œæˆï¼{Colors.RESET}")
        exit_code = 0
    else:
        print(f"\n{Colors.RED}{Colors.BOLD}âŒ å­˜åœ¨æµ‹è¯•å¤±è´¥ï¼Œè¯·æŸ¥çœ‹è¯¦ç»†æŠ¥å‘Š{Colors.RESET}")
        exit_code = 1

    # è¿”å›é€‚å½“çš„é€€å‡ºç 
    sys.exit(exit_code)

if __name__ == "__main__":
    main()